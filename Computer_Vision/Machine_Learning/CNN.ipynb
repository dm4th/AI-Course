{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-Built Historic Models\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 17:33:19.917982: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102967424/102967424 [==============================] - 295s 3us/step\n"
     ]
    }
   ],
   "source": [
    "# Initialize Model\n",
    "resnet_model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the ResNet50 Model on a Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "35363/35363 [==============================] - 0s 1us/step\n",
      "Predicted:\t[('n02106662', 'German_shepherd', 0.9987184), ('n02105412', 'kelpie', 0.0005585266), ('n02105162', 'malinois', 0.00041019832)]\n"
     ]
    }
   ],
   "source": [
    "img_path = './images/imagenet_images/dog.jpg'\n",
    "img = image.load_img(img_path, target_size=(224,224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = resnet_model.predict(x)\n",
    "\n",
    "# Decode the results into a list of tuples (class, description, probability)\n",
    "# This will create one such list for each sample in the batch\n",
    "print(f'Predicted:\\t{decode_predictions(preds, top=3)[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How About Multiple Images - Display Results Over the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper funtion to show an image with cv2\n",
    "def cv_show_img(title, image, wait=0):\n",
    "    cv2.namedWindow(title)\n",
    "    cv2.startWindowThread()\n",
    "    cv2.imshow(title, image)\n",
    "    cv2.waitKey(wait)\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "# Helper funtion to show multiple images at the same time\n",
    "def cv_show_mult_img(titleArr, imageArr, wait=0):\n",
    "    for i in range(len(titleArr)):\n",
    "        cv2.namedWindow(titleArr[i])\n",
    "        cv2.startWindowThread()\n",
    "        cv2.imshow(titleArr[i], imageArr[i])\n",
    "    cv2.waitKey(wait)\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV function that will display and image and it's predicted labels\n",
    "def draw_label(name, preds, img):\n",
    "    '''Displays the output of the preds alongside the original image'''\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_img = cv2.copyMakeBorder(img, 300, 0, 0, img.shape[1]+300, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "    width = img.shape[1]\n",
    "\n",
    "    for (i, pred) in enumerate(preds):\n",
    "        cv2.putText(expanded_img, str(name), (width + 50, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0,0,255), 2)\n",
    "        cv2.putText(expanded_img, f'{pred[1]} {pred[2]}', (width + 50, 50+((i+1)*50)), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0,0,255), 2)\n",
    "\n",
    "    cv_show_img(str(name), expanded_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 654ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n"
     ]
    }
   ],
   "source": [
    "imagenet_path = './images/imagenet_images/'\n",
    "files = [f for f in listdir(imagenet_path) if isfile(join(imagenet_path, f))]\n",
    "\n",
    "for f in files:\n",
    "    # Load image with tensorflow\n",
    "    img = image.load_img(f'{imagenet_path}{f}', target_size=(224,224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    # Load image with openCV\n",
    "    img2 = cv2.imread(f'{imagenet_path}{f}')\n",
    "    imageL = cv2.resize(img2, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Get preds\n",
    "    preds = resnet_model.predict(x)\n",
    "    predictions = decode_predictions(preds, top=3)[0]\n",
    "    draw_label('Predictions', predictions, imageL)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Compare ResNet to VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467096/553467096 [==============================] - 1822s 3us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import vgg16\n",
    "\n",
    "vgg_model = vgg16.VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n"
     ]
    }
   ],
   "source": [
    "# Similar loop to before, but also get VGG16 preds\n",
    "for f in files:\n",
    "    # Load image with tensorflow\n",
    "    img = image.load_img(f'{imagenet_path}{f}', target_size=(224,224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    # Load image with openCV\n",
    "    img2 = cv2.imread(f'{imagenet_path}{f}')\n",
    "    imageL = cv2.resize(img2, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Get VGG16 preds\n",
    "    preds_vgg16 = vgg_model.predict(x)\n",
    "    predictions_vgg16 = decode_predictions(preds_vgg16, top=3)[0]\n",
    "    draw_label('VGG 16 Predictions', predictions_vgg16, imageL)\n",
    "\n",
    "    # Get ResNet preds\n",
    "    preds_resnet = resnet_model.predict(x)\n",
    "    predictions_resnet = decode_predictions(preds_resnet, top=3)[0]\n",
    "    draw_label('ResNet Predictions', predictions_resnet, imageL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "We can use earlier pre-trained models as a starting point to train our own models. To do this we freeze the convolutional weights of a previous model and train an output convolusional layer on top of those weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To demonstrate we'll use the CIPHAR-10 dataset\n",
    "import os\n",
    "from __future__ import print_function\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Shape:\t(50000, 32, 32, 3)\n",
      "Train Samples:\t50000\n",
      "Test Samples:\t10000\n"
     ]
    }
   ],
   "source": [
    "# Data Dimensions\n",
    "print(f'X Train Shape:\\t{x_train.shape}')\n",
    "print(f'Train Samples:\\t{x_train.shape[0]}')\n",
    "print(f'Test Samples:\\t{x_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:\t0.0\n",
      "Max:\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Normalize Data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(f'Min:\\t{x_train.min()}\\nMax:\\t{x_train.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Train Shape:\t(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding for Output Labels\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "print(f'Y Train Shape:\\t{y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               3686912   \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,702,186\n",
      "Trainable params: 3,702,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile Model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=SGD(0.01),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 91s 56ms/step - loss: 1.9447 - accuracy: 0.2969 - val_loss: 1.7080 - val_accuracy: 0.3932\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 77s 49ms/step - loss: 1.6155 - accuracy: 0.4204 - val_loss: 1.4181 - val_accuracy: 0.4999\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 73s 47ms/step - loss: 1.4440 - accuracy: 0.4818 - val_loss: 1.3135 - val_accuracy: 0.5350\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 76s 48ms/step - loss: 1.3482 - accuracy: 0.5150 - val_loss: 1.2538 - val_accuracy: 0.5565\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 77s 49ms/step - loss: 1.2754 - accuracy: 0.5455 - val_loss: 1.2004 - val_accuracy: 0.5718\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 76s 48ms/step - loss: 1.2186 - accuracy: 0.5663 - val_loss: 1.1526 - val_accuracy: 0.5946\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 75s 48ms/step - loss: 1.1617 - accuracy: 0.5893 - val_loss: 1.1198 - val_accuracy: 0.6060\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 76s 49ms/step - loss: 1.1114 - accuracy: 0.6071 - val_loss: 1.0757 - val_accuracy: 0.6180\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 76s 49ms/step - loss: 1.0667 - accuracy: 0.6177 - val_loss: 1.0403 - val_accuracy: 0.6341\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 75s 48ms/step - loss: 1.0231 - accuracy: 0.6400 - val_loss: 1.0073 - val_accuracy: 0.6443\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "trained = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_test,y_test),\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.save('./model_objects/cifar_simple_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 1.0073 - accuracy: 0.6443\n",
      "Test Loss:\t1.0072827339172363\n",
      "Test Accuracy:\t0.6442999839782715\n"
     ]
    }
   ],
   "source": [
    "# Score Model\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(f'Test Loss:\\t{scores[0]}')\n",
    "print(f'Test Accuracy:\\t{scores[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Some of Our Guesses\n",
    "\n",
    "# Constants\n",
    "img_row, img_height, img_depth = 32, 32, 3\n",
    "color = True\n",
    "scale = 8\n",
    "\n",
    "# From the ciphar dataset\n",
    "guess_list = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'\n",
    "]\n",
    "\n",
    "# Load Model\n",
    "classifier = load_model('./model_objects/cifar_simple_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to draw our guess with the image\n",
    "def draw_guess(name, res, img, scale=scale, img_row=img_row, img_height=img_height):\n",
    "    BLACK = [0,0,0]\n",
    "    res = int(res)\n",
    "    pred = guess_list[res]\n",
    "\n",
    "    expanded_img = cv2.copyMakeBorder(img, 0, 0, 0, img.shape[0]*2, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "    if not color:\n",
    "        expanded_img = cv2.cvtColor(expanded_img, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.putText(expanded_img, pred, (300,80), cv2.FONT_HERSHEY_COMPLEX_SMALL, 3, (0,255,0), 2)\n",
    "    cv_show_img(name, expanded_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkout preds for 10 random images\n",
    "for i in range(10):\n",
    "    rand = np.random.randint(0,x_test.shape[0])\n",
    "    img = x_test[rand]\n",
    "    img_copy = cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    img = img.reshape(1, img_row, img_height, img_depth)\n",
    "\n",
    "    # Get Prediction\n",
    "    res = str(np.argmax(classifier.predict(img, 1, verbose=0)[0]))\n",
    "\n",
    "    # Display\n",
    "    draw_guess(\"Prediction\", res, img_copy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preds Aren't Great... Applying Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More imports\n",
    "from tensorflow.keras import callbacks, optimizers, Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 10\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([cv2.resize(x, (48, 48), interpolation=cv2.INTER_AREA) for x in x_train])\n",
    "X_test = np.array([cv2.resize(x, (48, 48), interpolation=cv2.INTER_AREA) for x in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding for Output Labels\n",
    "Y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "Y_test = to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 110s 2us/step\n"
     ]
    }
   ],
   "source": [
    "# Import base vgg16 model\n",
    "base_model = vgg16.VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,      # Don't include the top layer of the model so that we can add in the shape we need later\n",
    "    input_shape=(48,48,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Last Layer of the Base Model\n",
    "last_layer = base_model.get_layer('block3_pool').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we add a classification layer on top of it\n",
    "x = GlobalAveragePooling2D()(last_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in a new top layer that can take the inputs we want\n",
    "top_layer = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Construct model\n",
    "model = Model(base_model.input, top_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now all we have to do is iterate over the base model to freeze the layers so we don't train them\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 256)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,870,666\n",
      "Trainable params: 134,666\n",
      "Non-trainable params: 1,736,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the New Transferred Model\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how the trainable params are much lower than the total params - we froze the other ones because they're already learned\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our Data Generator to get our data\n",
    "train_datagen.fit(X_train)\n",
    "train_generator = train_datagen.flow(X_train,\n",
    "                                     y_train, \n",
    "                                     batch_size=BATCH_SIZE\n",
    "                                    )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255, horizontal_flip=False)\n",
    "\n",
    "val_datagen.fit(X_test)\n",
    "val_generator = val_datagen.flow(X_test,\n",
    "                                 y_test,\n",
    "                                 batch_size=BATCH_SIZE\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/dtjny68152z02rjhb55rxv300000gn/T/ipykernel_94507/2161546312.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 269s 167ms/step - loss: -48722.8633 - accuracy: 0.0124 - val_loss: -228977.8281 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Now train the model\n",
    "train_steps_per_epoch = X_train.shape[0] // BATCH_SIZE\n",
    "val_steps_per_epoch = X_test.shape[0] // BATCH_SIZE\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_steps_per_epoch,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
