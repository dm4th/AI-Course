{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper funtion to show an image with cv2\n",
    "def cv_show_img(title, image, wait=0):\n",
    "    cv2.namedWindow(title)\n",
    "    cv2.startWindowThread()\n",
    "    cv2.imshow(title, image)\n",
    "    cv2.waitKey(wait)\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "# Helper funtion to show multiple images at the same time\n",
    "def cv_show_mult_img(titleArr, imageArr, wait=0):\n",
    "    for i in range(len(titleArr)):\n",
    "        cv2.namedWindow(titleArr[i])\n",
    "        cv2.startWindowThread()\n",
    "        cv2.imshow(titleArr[i], imageArr[i])\n",
    "    cv2.waitKey(wait)\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxf = cv2.imread('./images/oxford.jpg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blurring & Sharpening\n",
    "- Helps computer vision algorithms work much better because they're very sensitive to edges\n",
    "- Blurring is averaging pixels over kernels in convolution\n",
    "- Sharpening is mphasizing the center points in kernels during convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 3x3 & 7x7 kernel to convolve over the image\n",
    "kernel3 = np.ones((3,3), np.uint8) / (3*3)\n",
    "kernel7 = np.ones((7,7), np.uint8) / (7*7)\n",
    "\n",
    "# Use cv2.filter2D to convolve over the image\n",
    "blurred3 = cv2.filter2D(oxf,-1,kernel3) # just always use -1 for image depth\n",
    "blurred7 = cv2.filter2D(oxf,-1,kernel7)\n",
    "\n",
    "cv_show_mult_img(['Original','3x3 Kernel Blur','7x7 Kernel Blur'],[oxf,blurred3,blurred7])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Blurring Methods\n",
    "- Gaussian - Blur based on the gaussian mean of the kernel\n",
    "- Median - take the median of all pixels in the kernel and replace the center pixel with that value\n",
    "- Bilateral - effective at noise removal\n",
    "- Average (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_avg = cv2.blur(oxf, (3,3))\n",
    "blur_gaus = cv2.GaussianBlur(oxf, (3,3), 0) # the last 0 defines the std dev of the Gaussian function used in blurring\n",
    "blur_med = cv2.medianBlur(oxf, 3)\n",
    "blur_b = cv2.bilateralFilter(oxf, 9, 75, 75) # 9 is just 3 * 3, the 75's are idk but should be the same\n",
    "\n",
    "cv_show_mult_img(\n",
    "    ['Original','Average Blur','Gaussian Blur','Median Blur','Bilateral Blur'],\n",
    "    [oxf,blur_avg,blur_gaus,blur_med,blur_b]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not super useful idk\n",
    "sharp_filter = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "sharpened = cv2.filter2D(oxf,-1,sharp_filter)\n",
    "\n",
    "cv_show_mult_img(['Original','Sharpened'],[oxf,sharpened])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding & Binarization\n",
    "- Binarization is changing the pixel values from 0-255 to 0-1 (Typically changed to either 0 or 255 based on some logic)\n",
    "- Thresholding is the act of converting an image to binary form based on some logic\n",
    "- Thresholding requires grayscale images\n",
    "\n",
    "#### Adaptive Thresholding - use an algo to figure out the best thresholding for your image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/gradient.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding Examples\n",
    "\n",
    "# 127 and up goes to black, rest goes to white\n",
    "ret, thresh1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "# Reverse\n",
    "ret, thresh2 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Values above 127 get sent to 127, rest stay at their values (grayscale)\n",
    "ret, thresh3 = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC)\n",
    "# Values below 127 go to 0, rest are unchanged\n",
    "ret, thresh4 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO)\n",
    "# Reverse\n",
    "ret, thresh5 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "cv_show_mult_img(\n",
    "    ['Original','1. Binary','2. Inverse Binary','3. Truncate','4. To Zero','5. Inverse To Zero'],\n",
    "    [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biggest downfall of thresholding is you need to provide the 127 value before running these functions\n",
    "\n",
    "We can use Adaptive thresholding to threshold more intelligently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "darwin = cv2.imread('./images/Origin_of_Species.jpg', 0)        # the 0 second arg loads the image as grayscale\n",
    "cv_show_img('Darwin',darwin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good practice to blur to remove noise in the image\n",
    "darwin = cv2.GaussianBlur(darwin, (3,3), 0)\n",
    "\n",
    "# Lets see a binary threshold to start\n",
    "ret, thresh_bin = cv2.threshold(darwin, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Thresholoding with adaptive threshold\n",
    "thresh_ada = cv2.adaptiveThreshold(darwin, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 5)\n",
    "\n",
    "# Otsu's algorithm for thresholding\n",
    "_, thresh_otsu = cv2.threshold(darwin, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv_show_mult_img(\n",
    "    ['Original', 'Binary Threshold','Adaptive Thresholding',\"Otsu's Thresholding\"],\n",
    "    [darwin, thresh_bin, thresh_ada, thresh_otsu]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilation & Erosion\n",
    "Dilation adds pixels to the boundaries of objects in an image, while erosion removes pixels from the boundaries of an image\n",
    "Reminder: these work better on black backgrounds with white objects... they reverse direction on white backgrounds with black objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cv2.imread('./images/opencv_inv.png')\n",
    "cv_show_img('Open CV', cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Kernel\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "erosion = cv2.erode(cv, kernel, iterations=1)\n",
    "dilation = cv2.dilate(cv, kernel, iterations=1)\n",
    "\n",
    "cv_show_mult_img(\n",
    "    ['Original','Eroded','Dilated'],\n",
    "    [cv,erosion,dilation]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection & Image Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxf = cv2.imread('./images/oxford.jpg', 0)\n",
    "height, width = oxf.shape[:2]\n",
    "\n",
    "# Sobel Edges\n",
    "sobel_x = cv2.Sobel(oxf, cv2.CV_64F, 0, 1, ksize=5)\n",
    "sobel_y = cv2.Sobel(oxf, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobel_or = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "\n",
    "# LaPlacian Edges\n",
    "laplacian = cv2.Laplacian(oxf, cv2.CV_64F)\n",
    "\n",
    "cv_show_mult_img(\n",
    "    ['Original','Sobel X','Sobel Y','Sobel OR','LaPlacian'],\n",
    "    [oxf,sobel_x,sobel_y,sobel_or,laplacian]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canny Edge Detection Works Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny Edge Detection uses gradient values as thresholds\n",
    "canny1 = cv2.Canny(oxf, 50, 120)\n",
    "canny2 = cv2.Canny(oxf, 10, 200)\n",
    "canny3 = cv2.Canny(oxf, 200, 240)\n",
    "canny4 = cv2.Canny(oxf, 70, 110)\n",
    "\n",
    "cv_show_mult_img(\n",
    "    ['Original','Canny Original','Canny Wide','Canny High','Canny Narrow'],\n",
    "    [oxf,canny1,canny2,canny3,canny4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
