{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung Detection Final Project\n",
    "Danny Mathieson\n",
    "\n",
    "### Project Contents\n",
    "\n",
    "##### [Project Setup](#section-1-project-setup)\n",
    "1. [Import Necessary Libraries](#1-import-necessary-libraries)\n",
    "2. [Plot sample images for all classes](#2-plot-sample-images-for-all-classes)\n",
    "3. [Plot the distribution of images across classes](#3-plot-the-distribution-of-images-across-classes)\n",
    "4. [Build Data Augmentation for the training data with translation, rescale, and flip - Rescale images to 48x48](#4-build-data-augmentation-for-the-training-data-with-translation-rescale-and-flip---rescale-images-to-48x48)\n",
    "5. [Build Data Augmentation for the test data with translation, rescale, and flip - Rescale images to 48x48](#5-build-data-augmentation-for-the-test-data-with-translation-rescale-and-flip---rescale-images-to-48x48)\n",
    "6. [Make a function to read directly from the train and test folders](#6-make-a-function-to-read-directly-from-the-train-and-test-folders)\n",
    "\n",
    "##### [Build Initial CNN](#section-2-build-initial-cnn)\n",
    "1. [Build a CNN with different filters, max pooling, dropout, and batch normalization layers](#1-build-a-cnn-with-different-filters-max-pooling-dropout-and-batch-normalization-layers)\n",
    "2. [Use ReLU as an activation function](#2-use-relu-as-an-activation-function)\n",
    "3. [Use Categorical Cross Entropy as a loss function](#3-use-categorical-cross-entropy-as-a-loss-function)\n",
    "4. [Use rmsprop as the optimizer](#4-use-rmsprop-as-the-optimizer)\n",
    "5. [Use Early stopping with a patience of 2 epochs on validation loss or validation accuracy](#5-use-early-stopping-with-a-patience-of-2-epochs-on-validation-loss-or-validation-accuracy)\n",
    "6. [Use 10 epochs](#6-use-10-epochs)\n",
    "7. [Train using a generator and test the accuracy on the test data at each epoch](#7-train-using-a-generator-and-test-the-accuracy-on-the-test-data-at-each-epoch)\n",
    "8. [Plot training & validation accuracy & loss](#8-plot-training--validation-accuracy--loss)\n",
    "9. [Observe Precision, Recall, F1-Score for all classes on both grayscale & color models - determine if the classes are good.](#9-observe-precision-recall-f1-score-for-all-classes-on-both-grayscale--color-models---determine-if-the-classes-are-good)\n",
    "\n",
    "##### [Transfer Learning - Mobile Net](#section-3-transfer-learning---mobile-net)\n",
    "1. [Prepare the dataset for the mobile-net model with color mode RGB](#1-prepare-the-dataset-for-the-mobile-net-model-with-color-mode-rgb)\n",
    "2. [Create an instance of the mobile-net pre-trained model](#2-create-an-instance-of-the-mobile-net-pre-trained-model)\n",
    "3. [Add a dense layer, dropout layer, and batch normalization layer on the pre-trained model](#3-add-a-dense-layer-dropout-layer-and-batch-normalization-layer-on-the-pre-trained-model)\n",
    "4. [Create a final output using the softmax activation function](#4-create-a-final-output-using-the-softmax-activation-function)\n",
    "5. [Change the batch size activation function and optimize as rmsprop - observe if the accuracy increases](#5-change-the-batch-size-activation-function-and-optimize-as-rmsprop---observe-if-the-accuracy-increases)\n",
    "6. [Change the loss function to categorical cross-entropy](#6-change-the-loss-function-to-categorical-cross-entropy)\n",
    "7. [Use an early stopping callback on the validation loss with a patience of 2 epochs to prevent overfitting](#7-use-an-early-stopping-callback-on-the-validation-loss-with-a-patience-of-2-epochs-to-prevent-overfitting)\n",
    "8. [Use 10 epochs](#8-use-10-epochs)\n",
    "9. [Train using a generator and test the accuracy on the test data at each epoch](#9-train-using-a-generator-and-test-the-accuracy-on-the-test-data-at-each-epoch)\n",
    "10. [Plot training & validation accuracy & loss](#10-plot-training--validation-accuracy--loss)\n",
    "11. [Observe Precision, Recall, F1-Score for all classes on both grayscale & color models - determine if the classes are good.](#11-observe-precision-recall-f1-score-for-all-classes-on-both-grayscale--color-models---determine-if-the-classes-are-good)\n",
    "\n",
    "##### [Transfer Learning - Densenet121](#section-4-transfer-learning---densenet121)\n",
    "1. [Prepare the dataset for the densenet121 model with image size 224x224x3](#1-prepare-the-dataset-for-the-densenet121-model-with-image-size-224x224x3)\n",
    "2. [Freeze the top layers of the pre-trained model](#2-freeze-the-top-layers-of-the-pre-trained-model)\n",
    "3. [Add a dense layer at the end of the pre-trained model, followed by a dropout layer and try various combinations to optimize accuracy](#3-add-a-dense-layer-at-the-end-of-the-pre-trained-model-followed-by-a-dropout-layer-and-try-various-combinations-to-optimize-accuracy)\n",
    "4. [Create a final output using the softmax activation function](#4-create-a-final-output-using-the-softmax-activation-function)\n",
    "5. [Change the loss function to categorical cross-entropy](#5-change-the-loss-function-to-categorical-cross-entropy)\n",
    "6. [Use Adam as the optimizer](#6-use-adam-as-the-optimizer)\n",
    "7. [Use Early Stopping on the validation loss with a patience of 2 epochs to prevent overfitting](#7-use-early-stopping-on-the-validation-loss-with-a-patience-of-2-epochs-to-prevent-overfitting)\n",
    "8. [Use 15 epochs with a batch size of 7 - tinker with these to optimize accuracy](#8-use-15-epochs-with-a-batch-size-of-7---tinker-with-these-to-optimize-accuracy)\n",
    "9. [Train using an image generator and test the accuracy on the test data at each epoch](#9-train-using-an-image-generator-and-test-the-accuracy-on-the-test-data-at-each-epoch)\n",
    "10. [Plot the training & validation accuracy & loss](#10-plot-the-training--validation-accuracy--loss)\n",
    "11. [Observe metrics Precision, Recall, F1-Score for all classes on both grayscale & color models - determine if the classes are good.](#11-observe-metrics-precision-recall-f1-score-for-all-classes-on-both-grayscale--color-models---determine-if-the-classes-are-good)\n",
    "\n",
    "##### [Final Step](#section-5-final-step)\n",
    "1. [Compare all of the models on the basis of accuracy, precision, recall, f1-score](#1-compare-all-of-the-models-on-the-basis-of-accuracy-precision-recall-f1-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set Style for Matplotlib plots\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.unpack_archive('./images/Dataset_Detection_of_Lung_Infection.zip', './images')\n",
    "os.rename('./images/data/test/healthy/','./images/data/test/Healthy/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Plot sample images for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Healthy', 'Type 1 disease', 'Type 2 disease']\n",
    "train_path = './images/data/train/'\n",
    "test_path = './images/data/test/'\n",
    "sample_images = 3\n",
    "\n",
    "for c in classes:\n",
    "    for i in range(sample_images):\n",
    "        img = load_img(train_path + c + '/' + os.listdir(train_path + c)[i])\n",
    "        x = img_to_array(img)\n",
    "        plt.title(f'{c}:\\t{i}')\n",
    "        plt.imshow(x/255.)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Plot the distribution of images across classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the number of images for each class in the test & train set\n",
    "def get_num_images(path):\n",
    "    num_images = {}\n",
    "    for c in classes:\n",
    "        num_images[c] = len(os.listdir(path + c))\n",
    "    return num_images\n",
    "\n",
    "class_counts = {}\n",
    "for path in [('Train',train_path), ('Test',test_path)]:\n",
    "    class_counts[path[0]] = get_num_images(path[1])\n",
    "\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of images for each class in the test & train set\n",
    "for path in class_counts.keys():\n",
    "    plt.bar(class_counts[path].keys(), class_counts[path].values())\n",
    "    plt.title(f'Number of Images in {path} Set')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Build Data Augmentation for the training data with translation, rescale, and flip - Rescale images to 48x48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image generator to augment the images in the training set\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Point the training generator to the training set to create augmented images at training time\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(48,48),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Build Data Augmentation for the test data with translation, rescale, and flip - Rescale images to 48x48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image generator to augment the images in the test set\n",
    "test_gen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "# Point the test generator to the test set to create augmented images at test time\n",
    "test_generator = test_gen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(48,48),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Make a function to read directly from the train and test folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read directly from the train & test generators\n",
    "def read_from_generator(generator):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(generator)):\n",
    "        X.append(generator[i][0])\n",
    "        y.append(generator[i][1])\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    y = np.concatenate(y, axis=0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Build Initial CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Build a CNN with different filters, max pooling, dropout, and batch normalization layers\n",
    "##### 2. Use ReLU as an activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.metrics import categorical_accuracy, Precision, Recall\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Define Tracking Metrics during Training\n",
    "METRICS = [\n",
    "    categorical_accuracy,\n",
    "    Precision(name='precision'),\n",
    "    Recall(name='recall')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(48,48,3)))\n",
    "\n",
    "# Convolutional Layer 1\n",
    "model.add(Conv2D(64, (3,3), activation=relu, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Convolutional Layer 2\n",
    "model.add(Conv2D(32, (3,3), activation=relu, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Convolutional Layer 3\n",
    "model.add(Conv2D(16, (3,3), activation=relu, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense Layer 1\n",
    "model.add(Dense(128, activation=relu))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Dense Layer 2\n",
    "model.add(Dense(64, activation=relu))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(3, activation=softmax))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Use Categorical Cross Entropy as a loss function\n",
    "##### 4. Use rmsprop as the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=categorical_crossentropy,\n",
    "    optimizer=RMSprop(learning_rate=0.001),\n",
    "    metrics=METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Use an early stopping with a patience of 2 epochs on validation loss or validation accuracy\n",
    "##### 6. Use 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "mc = ModelCheckpoint('./model_objects/initial_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Train using a generator and test the accuracy on the test data at each epoch\n",
    "##### 8. Plot training & validation accuracy & loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[\n",
    "        es, \n",
    "        mc, \n",
    "        PlotLossesKerasTF()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Observe Precision, Recall, F1-Score for all classes on both grayscale & color models - determine if the classes are good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn classification report to evaluate the model\n",
    "best_model = load_model('./model_objects/initial_model.h5')\n",
    "y_pred = best_model.predict(test_generator)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = test_generator.classes\n",
    "print(classification_report(y_true, y_pred, target_names=classes))\n",
    "print(f'Precision:\\t{precision_score(y_true, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t\\t{recall_score(y_true, y_pred, average=\"macro\")}')\n",
    "print(f'F1 Score:\\t{f1_score(y_true, y_pred, average=\"macro\")}')\n",
    "\n",
    "# The model is simply predicting the majority class for all images (i.e. everyone has Type 1 Disease)\n",
    "# The classes are quite bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Transfer Learning - Mobile Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Prepare the dataset for the mobile-net model with color mode RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MobileNetV2\n",
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image generator for the training set & test set for the mobilenet model\n",
    "mobilenet_train_generator = train_gen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224,224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "mobilenet_test_generator = test_gen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(224,224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Create an instance of the mobile-net pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "mobilenet_base_model = MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Freeze the base model\n",
    "for layer in mobilenet_base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Add a dense layer, dropout layer, and batch normalization layer on the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model on top with a dense layer, dropout layer, and batch normalization layer on top of the base model\n",
    "x = BatchNormalization()(mobilenet_base_model.output)\n",
    "x = MaxPooling2D((2,2))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation=relu)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Create a final output using the softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor = Dense(3, activation=softmax)(x)\n",
    "mobilenet_model = Model(inputs=mobilenet_base_model.input, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Change the batch size activation function and optimize as rmsprop - observe if the accuracy increases\n",
    "##### 6. Change the loss function to categorical cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model.compile(\n",
    "    loss=categorical_crossentropy,\n",
    "    optimizer=RMSprop(learning_rate=0.001),\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "mobilenet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Use an early stopping callback on the validation loss with a patience of 2 epochs to prevent overfitting\n",
    "##### 8. Use 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "mc = ModelCheckpoint('./model_objects/mobilenet_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Train using a generator and test the accuracy on the test data at each epoch\n",
    "##### 10. Plot training & validation accuracy & loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model.fit(\n",
    "    mobilenet_train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=mobilenet_test_generator,\n",
    "    callbacks=[\n",
    "        es,\n",
    "        mc,\n",
    "        PlotLossesKerasTF()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Observe Precision, Recall, F1-Score for all classes on both grayscale & color models - determine if the classes are good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn classification report to evaluate the mobilenet model\n",
    "best_mobilenet_model = load_model('./model_objects/mobilenet_model.h5')\n",
    "y_pred = best_mobilenet_model.predict(mobilenet_test_generator)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = mobilenet_test_generator.classes\n",
    "print(classification_report(y_true, y_pred, target_names=classes))\n",
    "print(f'Precision:\\t{precision_score(y_true, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t\\t{recall_score(y_true, y_pred, average=\"macro\")}')\n",
    "print(f'F1 Score:\\t{f1_score(y_true, y_pred, average=\"macro\")}')\n",
    "\n",
    "# F1 score is rather low still for the mobilenet model.\n",
    "# This comes despite rather high categorical accuracy (0.924)\n",
    "# We are predicting disease so we should expect a lower F1 Score - but Recall & Precision are both low too\n",
    "# We should expect better precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Transfer Learning - Densenet121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Prepare the dataset for the densenet121 model with image size 224x224x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import denseNet121\n",
    "from tensorflow.keras.applications import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image generator for the training set & test set for the densenet model\n",
    "densenet_train_generator = train_gen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224,224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "densenet_test_generator = test_gen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(224,224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the DenseNet121 model\n",
    "densenet_base_model = DenseNet121(input_shape=(224,224,3), include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Freeze the top layers of the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the layers in the base model and freeze them\n",
    "for layer in densenet_base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Add a dense layer at the end of the pre-trained model, followed by a dropout layer and try various combinations to optimize accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a dense layer followed by a dropout layer on top of the base model\n",
    "x = Dropout(0.2)(densenet_base_model.output)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation=relu)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Create a final output using the softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer and build the model\n",
    "output_tensor = Dense(3, activation=softmax)(x)\n",
    "densenet_model = Model(inputs=densenet_base_model.input, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Change the loss function to categorical cross-entropy\n",
    "##### 6. Use Adam as the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model.compile(\n",
    "    loss=categorical_crossentropy,\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "densenet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Use Early Stopping on the validation loss with a patience of 2 epochs to prevent overfitting\n",
    "##### 8. Use 15 epochs with a batch size of 7 - tinker with these to optimize accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "mc = ModelCheckpoint('./model_objects/densenet_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Train using an image generator and test the accuracy on the test data at each epoch\n",
    "##### 10. Plot the training & validation accuracy & loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model.fit(\n",
    "    densenet_train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=densenet_test_generator,\n",
    "    callbacks=[\n",
    "        es,\n",
    "        mc,\n",
    "        PlotLossesKerasTF()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Observe metrics Precision, Recall, F1-Score for all classes on both grayscale & color models - determine if the classes are good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn classification report to evaluate the densenet model\n",
    "best_densenet_model = load_model('./model_objects/densenet_model.h5')\n",
    "y_pred = best_densenet_model.predict(densenet_test_generator)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = densenet_test_generator.classes\n",
    "print(classification_report(y_true, y_pred, target_names=classes))\n",
    "print(f'Precision:\\t{precision_score(y_true, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t\\t{recall_score(y_true, y_pred, average=\"macro\")}')\n",
    "print(f'F1 Score:\\t{f1_score(y_true, y_pred, average=\"macro\")}')\n",
    "\n",
    "# Definitievely the best model so far despite lower categorical accuracy (0.697 on the validation set when I ran it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5: Final Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Compare all of the models on the basis of accuracy, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to evaluate the models and store their metrics in an output dictionary\n",
    "def evaluate_model(model, model_name, test_generator, output_dict):\n",
    "    y_pred = model.predict(test_generator)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_true = test_generator.classes\n",
    "    output_dict['Accuracy'][model_name] = accuracy_score(y_true, y_pred)\n",
    "    output_dict['Precision'][model_name] = precision_score(y_true, y_pred, average='macro')\n",
    "    output_dict['Recall'][model_name] = recall_score(y_true, y_pred, average='macro')\n",
    "    output_dict['F1 Score'][model_name] = f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the key metrics for each model\n",
    "metric_dict = {\n",
    "    'Accuracy': {},\n",
    "    'Precision': {},\n",
    "    'Recall': {},\n",
    "    'F1 Score': {}\n",
    "}\n",
    "\n",
    "# Loop over the models and evaluate them, storing the metrics in the dictionary\n",
    "for model, model_name, generator in zip(\n",
    "    [best_model, best_mobilenet_model, best_densenet_model], \n",
    "    ['Initial Model', 'MobileNet Model', 'DenseNet Model'],\n",
    "    [test_generator, mobilenet_test_generator, densenet_test_generator]\n",
    "):\n",
    "    evaluate_model(model, model_name, generator, metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each of the metrics for each model\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "for i, metric in enumerate(metric_dict.keys()):\n",
    "    ax = axes[i//2, i%2]\n",
    "    ax.bar(metric_dict[metric].keys(), metric_dict[metric].values())\n",
    "    ax.set_title(metric)\n",
    "    ax.set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Notes:\n",
    "- The intial model was the most accurate simply because it predicted the majority class every time\n",
    "- The DenseNet model was able to achieve slightly better Recall & Precision leading to a much better F1 Score\n",
    "- All of the models do not perform very well...\n",
    "\n",
    "### Model Improvements:\n",
    "- I'd probably use some class weights in the modeling steps to further highlight the healthy sets of lungs. Even though the test & train sets both had mostly diseased pictures, I'm not sure that's how it would be in practice\n",
    "- I'd also optimize even more for F1-Score, particularly in the initial model\n",
    "- I'd love to grayscale the training images for the transfer learning base models, but alas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
